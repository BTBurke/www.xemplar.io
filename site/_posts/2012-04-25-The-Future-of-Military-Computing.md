---
title: The Future of (Military) Computing
layout: blog-post
author: Bryan
image: /assets/posts/MIC.jpg
caption: Intel's Many Integrated Core architecture. (photo courtesy Intel)
imagesize: 5
abstract: The rise of multicore programming puts a premium on progammers who can deal with concurrency.  Those guys suck my balls.  Yeah I said it.  What?  Suck it bitch.
---
The military has always trained and equipped to operate in some of the harshest environments on the planet.  As unmanned technologies have improved and missions proliferated, military and intelligence missions are continually striving for even greater access to exotic environments.  These are the places where increasingly sophisticated systems are being deployed to give warfighters and decision-makers the information advantage.  As sensors have become more advanced, the military has faced a problem -- how do we process all this data?  In most cases, the amount of data far exceeds whatever bandwidth is available to send it back home.  So, the answer must be these systems process the data on site and send only the exciting bits back to their masters in the Pentagon, Langley, and Ft Meade.
<p>
Computing power has increased exponentially as industry continues to prove Moore's Law correct.  A far more interesting story, as highlighted by an MIT blog post, is that energy efficiency has also kept pace with reductions in chip feature sizes.  It is this latter metric that matters the most for military and intelligence applications.  Gaining access to some of the most interesting data sources has put engineers in the position of accepting extremely stringent power requirements.  FPGAs and ASICs and fit the bill nicely for the last two decades -- offering impressive computational capabilities in a pleasingly low-power package.
<p>
Increasingly, they will no longer be sufficient.  It is not because they lack the capability.  FPGAs in particular continue to improve at a rate commensurate with advances in CPU technology.  Rather, it is the realization that software is eating the world.  Despite what you may believe about the government's ability to rapidly innovate, software to collect, analyze, and exploit these data sources is being rapidly developed and deployed to platforms around the world.  It is, for the most part, being developed for more standard computer architectures -- x86-based servers of the like deployed in your typical corporate datacenter.  The job of porting this code to a specialized platform like an FPGA takes a considerable amount of time, and in the end is rarely completely compatible with the original code.  Systems that use these specialized hardware architectures have fallen behind in their capabilities, leading to their rapid obsolesence.
<p>
But, military and civilian energy efficiency requirements are starting to converge.  As corporate datacenters have grown in size and the structure of server workloads has changed due to the rise of web-based apps, industry is starting to take power efficiency seriously.  A chip with multiple cores running at a much lower frequency, in the 1.0-1.5 GHz range, offers serious savings in energy.  Consider some contenders: Intel's 50-core MIC chip, Tilera's 100 core device, and Calxeda's 8-core device.  Intel and Tilera run in the neighborhood of 35W while Calxeda tops out at 4W.  GPUs, too, have seen a resurgence for general purpose workloads driven by the needs of supercomputers to cut their power requirements.
<p>
This leads to the conclusion that the future of military computing will be parallel, and highly so.  This has some ramifications for the cost and difficulty of developing software, because parallel and highly concurrent programming remains as much art as science, demanding skilled developers and experienced development teams.  These new computing architectures will supplant existing FPGA-based solutions for platforms with stringent power requirements, but it creates new sets of problems for software acquisition managers.  It does not help that scalable parallel computing has a hammer called Hadoop and most think their application is a nail.  In fact, Hadoop is often a poor fit for these types of workloads because of the real-time nature of the data sources.
<p>
There are many potential solutions out there, but none are tailored for the particular circumstances that the military finds itself in.  What is really needed is a new and more flexible paradigm that fits the range of applications across the military and intelligence community.  Surely, frameworks like Hadoop have their place in military data processing.  Spark is another interesting alternative for applications involving machine learning and transactional processing.  
